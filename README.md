# ğŸ“ Text Analyzer CLI

A powerful **Python-based Command Line Interface (CLI)** that demonstrates **core NLP preprocessing concepts** with beautiful Rich-based output and structured JSON support.

This project is **fully Dockerized**, making it portable, reproducible, and runnable on any machine without installing Python or dependencies.

---

## ğŸš€ Features

### ğŸ”¤ Tokenization

* Sentence tokens
* Word tokens
* LLM token estimation with cost

### ğŸ·ï¸ Part-of-Speech (POS) Tagging

* POS tags with human-readable descriptions

### ğŸ¯ Named Entity Recognition (NER)

* Entity detection (PERSON, ORG, GPE, etc.)
* BIO tagging (B- / I- / O)

### ğŸŒ¿ Stemming

* Porter
* Snowball
* Lancaster
* Invalid stems marked with âŒ

### ğŸŒ³ Lemmatization

* POS-aware lemmatization

### ğŸ”¬ Stem vs Lemma Comparison

### ğŸ“Š Full Analysis Command

* Combines all NLP steps
* Rich tables + timing

### ğŸ“ Disk I/O Support

* Read input from text files
* Save output as JSON files

### ğŸ“¦ JSON Output Mode

* Machine-readable output for pipelines

### ğŸ§ª Unit Tested

* All tests passing with Pytest

### ğŸ³ Dockerized

* No local Python or dependencies required
* Consistent execution across systems
* Supports volume mounting for input/output

---

## ğŸ“ Project Structure

```text
text-analyzer/
â”œâ”€â”€ main.py                 # Application entry point
â”œâ”€â”€ conftest.py             
â”œâ”€â”€ app/                    # Core application logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py              # Typer + Rich CLI commands
â”‚   â”œâ”€â”€ tokenizer.py        # Word, sentence & LLM tokenization
â”‚   â”œâ”€â”€ pos_tagger.py       # POS tagging
â”‚   â”œâ”€â”€ lemmatizer.py       # POS-aware lemmatization
â”‚   â”œâ”€â”€ stemmer.py          # Porter, Snowball, Lancaster
â”‚   â””â”€â”€ ner.py              # NER + BIO tagging
â”‚
â”œâ”€â”€ tests/                  # Pytest test cases
â”‚   â”œâ”€â”€ test_tokenizer.py
â”‚   â”œâ”€â”€ test_pos.py
â”‚   â”œâ”€â”€ test_lemmatizer.py
â”‚   â”œâ”€â”€ test_stemmer.py
â”‚   â””â”€â”€ test_ner.py
â”‚
â”œâ”€â”€ Dockerfile              # Docker image definition
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation (Local â€“ Without Docker)

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/aryika78/text-analyzer.git
cd text-analyzer
```

### 2ï¸âƒ£ Create and activate virtual environment

```bash
python -m venv venv
```

**Windows**

```bash
venv\Scripts\activate
```

**Linux / macOS**

```bash
source venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ³ Docker Usage (Recommended)

### ğŸ”¹ Build Docker Image

```bash
docker build -t text-analyzer-cli .
```

### ğŸ”¹ Run CLI Command in Container

```bash
docker run --rm text-analyzer-cli tokenize "Dr. Strange opened a portal"
```

### ğŸ”¹ Run with Input File (Volume Mount)

```bash
docker run --rm \
  -v ${PWD}/input.txt:/app/input.txt \
  -v ${PWD}/docker-output:/app/docker-output \
  text-analyzer-cli analyze --file input.txt --out docker-output/result.json
```

âœ” Input taken from host
âœ” Output saved back to host
âœ” No container state retained

---

## ğŸ§  CLI Usage (Local or Docker)

```bash
python main.py <command> [OPTIONS]
```

---

### ğŸ”¤ Tokenization

```bash
python main.py tokenize "Dr. Strange opened a portal!"
```

âœ” Sentence tokens
âœ” Word tokens
âœ” LLM token estimate + cost

---

### ğŸ·ï¸ POS Tagging

```bash
python main.py pos "Naruto trained hard at the academy"
```

Displays token, POS tag, and description in a Rich table.

---

### ğŸ¯ Named Entity Recognition

```bash
python main.py ner "Elon Musk founded SpaceX in California"
```

* Detected entities
* BIO tags per token

---

### ğŸŒ¿ Stemming

```bash
python main.py stem "running studies easily happiness"
```

Shows all three stemming algorithms with âŒ for invalid stems.

---

### ğŸŒ³ Lemmatization

```bash
python main.py lemmatize "The Avengers were fighting Thanos"
```

POS-aware lemmatization output.

---

### ğŸ”¬ Compare: Stemming vs Lemmatization

```bash
python main.py compare "running studies better easily"
```

Includes:

* Winner per word
* Summary statistics

---

### ğŸ“Š Full Analysis

```bash
python main.py analyze "Tony Stark built Jarvis in Malibu"
```

Combines:

* Tokenization
* POS + Lemmas
* Stemming
* NER
* BIO tags
* Execution time

---

### ğŸ“ Read Input from File

```bash
python main.py analyze --file input.txt
```

âœ” Useful for large texts
âœ” Enables batch processing
âœ” Real-world pipeline friendly

---

### ğŸ’¾ Save Output to JSON

```bash
python main.py analyze --file input.txt --out result.json
```

* Output is pure JSON
* Can be consumed by APIs, ML pipelines, or dashboards

---

### ğŸ§¾ JSON Output Mode

```bash
python main.py analyze "Tony Stark built Jarvis in Malibu" --json-output
```

Prints structured JSON directly to the terminal.

---

## ğŸ§ª Running Tests

```bash
pytest -v
```

âœ… All tests passing
âœ… Covers tokenization, POS, NER, stemming, lemmatization

---

## ğŸ“Œ Tech Stack

* Python 3.10+
* Typer (CLI framework)
* Rich (terminal UI)
* spaCy
* NLTK
* Pytest
* Docker

---

## ğŸ‘©â€ğŸ’» Author

**Aryika Patni**

> This project was built to demonstrate real-world NLP pipelines, clean CLI design, testing discipline, and production-ready Dockerization.
